{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch.neuron\n",
    "\n",
    "# BERTモデル及び、tokenizerのの読み込み\n",
    "bert_path = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_path)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(bert_path, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 128])\n",
      "attention_mask: torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:There are 3 ops of 1 different types in the TorchScript that are not compiled by neuron-cc: aten::embedding, (For more information see https://github.com/aws/aws-neuron-sdk/blob/master/release-notes/neuron-cc-ops/neuron-cc-ops-pytorch.md)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 563, fused = 546, percent fused = 96.98%\n",
      "INFO:Neuron:Number of neuron graph operations 1596 did not match traced graph 1308 - using heuristic matching of hierarchical information\n",
      "INFO:Neuron:Compiling function _NeuronGraph$2092 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ubuntu/pytorch_venv/bin/neuron-cc compile /tmp/tmp7hklhmbz/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /tmp/tmp7hklhmbz/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"], \"2:0\": [[32000, 768], \"float32\"]}, \"outputs\": [\"BertOnlyMLMHead_11/BertLMPredictionHead_1/Linear_4/aten_linear/Add:0\"]} --verbose 35'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      ".....\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:skip_inference_context for tensorboard symbols at /home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py:305 tb_parse\n",
      "INFO:Neuron:Number of neuron graph operations 1596 did not match traced graph 1308 - using heuristic matching of hierarchical information\n",
      "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 563, compiled = 546, percent compiled = 96.98%\n",
      "INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
      "INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
      "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 96\n",
      "INFO:Neuron: => aten::add: 36\n",
      "INFO:Neuron: => aten::contiguous: 12\n",
      "INFO:Neuron: => aten::div: 12\n",
      "INFO:Neuron: => aten::dropout: 37\n",
      "INFO:Neuron: => aten::gelu: 13\n",
      "INFO:Neuron: => aten::layer_norm: 26\n",
      "INFO:Neuron: => aten::linear: 74\n",
      "INFO:Neuron: => aten::matmul: 24\n",
      "INFO:Neuron: => aten::permute: 48\n",
      "INFO:Neuron: => aten::size: 96\n",
      "INFO:Neuron: => aten::softmax: 12\n",
      "INFO:Neuron: => aten::transpose: 12\n",
      "INFO:Neuron: => aten::view: 48\n",
      "INFO:Neuron:Not compiled operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 1 [supported]\n",
      "INFO:Neuron: => aten::add: 3 [supported]\n",
      "INFO:Neuron: => aten::embedding: 3 [not supported]\n",
      "INFO:Neuron: => aten::mul: 1 [supported]\n",
      "INFO:Neuron: => aten::rsub: 1 [supported]\n",
      "INFO:Neuron: => aten::size: 1 [supported]\n",
      "INFO:Neuron: => aten::slice: 4 [supported]\n",
      "INFO:Neuron: => aten::to: 1 [supported]\n",
      "INFO:Neuron: => aten::unsqueeze: 2 [supported]\n",
      "INFO:Neuron:skip_inference_context for tensorboard symbols at /home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py:305 tb_parse\n",
      "INFO:Neuron:Number of neuron graph operations 62 did not match traced graph 106 - using heuristic matching of hierarchical information\n"
     ]
    }
   ],
   "source": [
    "# コンパイル時に使用するダミーtext。モデルに合わせたtokenizer.mask_tokenを使用すること\n",
    "sample_input = \"これはtrace時[MASK]\"\n",
    "sample_input2 = \"使うためのダミーテキストですねこれは激熱\"\n",
    "\n",
    "# 入力の最大系列長を事前に指定する\n",
    "# inputs['input_ids'].size() -> torch.Size([1, 256])\n",
    "# に統一している。もっと長い入力でコンパイルをかけたい場合は、max_lengthを変更して\n",
    "max_length = 128\n",
    "inputs = tokenizer.encode_plus(\n",
    "   sample_input,\n",
    "   sample_input2,\n",
    "   return_tensors=\"pt\",\n",
    "   padding=\"max_length\",\n",
    "   max_length=max_length,\n",
    "   truncation=True\n",
    ")\n",
    "tuple_inputs = inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs[\"token_type_ids\"]\n",
    "print(\"input_ids:\", inputs[\"input_ids\"].size())\n",
    "print(\"attention_mask:\", inputs[\"attention_mask\"].size())\n",
    "\n",
    "# コンパイル (Neuron)\n",
    "model_neuron = torch.neuron.trace(model, tuple_inputs)\n",
    "# torch.jitの場合 (CPU)\n",
    "# traced_model = torch.jit.trace(model, example_input, strict=False)\n",
    "\n",
    "# neuton実行用モデルの保存\n",
    "# model_neuron.save(\"bert_neuron.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]]),)\n"
     ]
    }
   ],
   "source": [
    "#実験\n",
    "outputs = model_neuron(*tuple_inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.14 ('pytorch_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "309b54d1989123497a6650a8753c169a3d44f3531b745506f88f30eda76a10a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
