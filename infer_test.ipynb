{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b870e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig, pipeline\n",
    "import torch.neuron\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from proofreading import make_tokens, insert_mask_to_tokens, replace_mask_to_tokens, make_senetence_from_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30dc61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "text = \"これでいけなかったらもうどうしていいのかわからないよ頼むから通ってくれ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a844fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3f7573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'これはtrace時に[MASK]使うためのダミーテキストです'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token\n",
    "sample_input = f\"これはtrace時に{tokenizer.mask_token}使うためのダミーテキストです\"\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b785dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neuron = torch.jit.load('bert_neuron.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f509aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=AwsNeuronGraphModule\n",
       "  (_NeuronGraph#82): RecursiveScriptModule(original_name=NeuronModuleV2)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "861c4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_tokens = make_tokens(text=text, tokenizer=tokenizer2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62bedda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_text = make_senetence_from_tokens(insert_mask_to_tokens(i=5, mask_token=\"[MASK]\", tokens=corrected_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "530be938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'これでいけなかったら[MASK]もうどうしていいのかわからないよ頼むから通ってくれ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "822a7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "   text=masked_text,\n",
    "   return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1318ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = \"これはtrace時に[MASK]使うためのダミーテキストですねこれは激熱\"\n",
    "# 入力の最大系列長を事前に指定する\n",
    "max_length = 256\n",
    "inputs = tokenizer(\n",
    "   text=sample_input,\n",
    "   return_tensors=\"pt\",\n",
    "   padding=\"max_length\",\n",
    "   max_length=max_length,\n",
    "   truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b25b687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,   171,     9, 19551,  2953,    72,     7,     4,  3002,    82,\n",
       "             5,   314,  1659, 10306,  2992,  1852,   171,     9,  1762,  1583,\n",
       "             3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs['input_ids'].size()\n",
    "# inputs['attention_mask'].size()\n",
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cd695e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/torch_neuron/runtime/___torch_mangle_442.py\", line 37, in fallback_function\n    _16 = torch.slice(_15, 1, 0, _13)\n    _17 = torch.embedding(CONSTANTS.c5, argument_1, 0)\n    _18 = torch.add(_17, torch.embedding(CONSTANTS.c6, _4))\n          ~~~~~~~~~ <--- HERE\n    _19 = torch.add(_18, torch.embedding(CONSTANTS.c7, _16))\n    model = _NeuronGraph_82.model\n\nTraceback of TorchScript, original code (most recent call last):\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/resolve_function.py(68): func_from_schema\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(330): __call__\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(207): run_op\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(196): __call__\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/runtime.py(69): forward\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/jit/_trace.py(965): trace_module\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/jit/_trace.py(750): trace\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py(307): tb_parse\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py(533): tb_graph\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/decorators.py(482): maybe_generate_tb_graph_def\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/convert.py(513): maybe_determine_names_from_tensorboard\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/convert.py(200): trace\ncompile_model.py(30): <module>\nRuntimeError: The size of tensor a (256) must match the size of tensor b (16) at non-singleton dimension 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2567/22608884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_neuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/torch_neuron/runtime/___torch_mangle_442.py\", line 37, in fallback_function\n    _16 = torch.slice(_15, 1, 0, _13)\n    _17 = torch.embedding(CONSTANTS.c5, argument_1, 0)\n    _18 = torch.add(_17, torch.embedding(CONSTANTS.c6, _4))\n          ~~~~~~~~~ <--- HERE\n    _19 = torch.add(_18, torch.embedding(CONSTANTS.c7, _16))\n    model = _NeuronGraph_82.model\n\nTraceback of TorchScript, original code (most recent call last):\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/resolve_function.py(68): func_from_schema\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(330): __call__\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(207): run_op\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/graph.py(196): __call__\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/runtime.py(69): forward\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/jit/_trace.py(965): trace_module\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch/jit/_trace.py(750): trace\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py(307): tb_parse\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py(533): tb_graph\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/decorators.py(482): maybe_generate_tb_graph_def\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/convert.py(513): maybe_determine_names_from_tensorboard\n/home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/convert.py(200): trace\ncompile_model.py(30): <module>\nRuntimeError: The size of tensor a (256) must match the size of tensor b (16) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "output = model_neuron(*(inputs['input_ids'],inputs['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cf96e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3828, -0.3477],\n",
       "          [-0.5312, -0.1289],\n",
       "          [-0.2158, -0.2500],\n",
       "          [-0.3223, -0.5117],\n",
       "          [-0.5000, -0.2871],\n",
       "          [-0.4062, -0.0067],\n",
       "          [-0.7422, -0.0522],\n",
       "          [-0.5352, -0.2930],\n",
       "          [-0.5312, -0.1748],\n",
       "          [-0.3359, -0.5156],\n",
       "          [-0.6328, -0.3926],\n",
       "          [-0.3184, -0.3789],\n",
       "          [-0.5703, -0.5352],\n",
       "          [-0.2324, -0.0605],\n",
       "          [-0.6797, -0.0123],\n",
       "          [-0.4492, -0.1943]]]),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9a9abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.batch_encode_plus(text,max_length=256,padding='max_length', truncation=True)\n",
    "tokens = tokenizer.batch_encode_plus(text,max_length=256,padding='max_length')\n",
    "  \n",
    "text_seq = torch.tensor(tokens['input_ids'])\n",
    "text_mask = torch.tensor(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c9493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 27,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_seq.size())\n",
    "text_seq[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a78b0033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df38324613ce4c4ea6354901928d0942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c28bd023fb46a4b09ce7143ddb48f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93605a83653483bb03a437ba8a5446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e62e14ada43f39e978c7d71e87724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed9d18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b43d8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = torch.argmax(output[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "918b7f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4623)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a26716",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.softmax(logits, dim=1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a667d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32684/2100260326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch_venv/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_id_to_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_venv/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;31m# See gh-54457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration over a 0-d tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc25376",
   "metadata": {},
   "outputs": [],
   "source": [
    "##以下、tokenizer用の入力形式統一テスト\n",
    "max_length = 256\n",
    "sample_input = \"これはtrace時に[MASK]使うためのダミーテキストです\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "910a112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "   text=sample_input,\n",
    "   return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701df859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "len(inputs)\n",
    "print(inputs['input_ids'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a25438d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"これでいけなかったらもうどうしていいのかわからないよ頼むから通ってくれ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "949c3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "   text=text,\n",
    "   return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    max_length=max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040e9127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "len(inputs)\n",
    "print(inputs['input_ids'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63872822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Neuron PyTorch)",
   "language": "python",
   "name": "pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
